var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
import { Behaviour, GameObject } from "./Component";
import * as THREE from "three";
import { serializable } from "../engine/engine_serialization_decorator";
import { Object3D, ShaderMaterial, Texture, Vector2, Vector4 } from "three";
import { awaitInput } from "../engine/engine_input_utils";
import { getParam } from "../engine/engine_utils";
import { Renderer } from "./Renderer";
import { getWorldScale } from "../engine/engine_three_utils";
import { ObjectUtils, PrimitiveType } from "../engine/engine_create_objects";
const debug = getParam("debugvideo");
export var AspectMode;
(function (AspectMode) {
    AspectMode[AspectMode["None"] = 0] = "None";
    AspectMode[AspectMode["AdjustHeight"] = 1] = "AdjustHeight";
    AspectMode[AspectMode["AdjustWidth"] = 2] = "AdjustWidth";
})(AspectMode || (AspectMode = {}));
export var VideoSource;
(function (VideoSource) {
    /// <summary>
    ///   <para>Use the current clip as the video content source.</para>
    /// </summary>
    VideoSource[VideoSource["VideoClip"] = 0] = "VideoClip";
    /// <summary>
    ///   <para>Use the current URL as the video content source.</para>
    /// </summary>
    VideoSource[VideoSource["Url"] = 1] = "Url";
})(VideoSource || (VideoSource = {}));
export var VideoAudioOutputMode;
(function (VideoAudioOutputMode) {
    VideoAudioOutputMode[VideoAudioOutputMode["None"] = 0] = "None";
    VideoAudioOutputMode[VideoAudioOutputMode["AudioSource"] = 1] = "AudioSource";
    VideoAudioOutputMode[VideoAudioOutputMode["Direct"] = 2] = "Direct";
    VideoAudioOutputMode[VideoAudioOutputMode["APIOnly"] = 3] = "APIOnly";
})(VideoAudioOutputMode || (VideoAudioOutputMode = {}));
export var VideoRenderMode;
(function (VideoRenderMode) {
    VideoRenderMode[VideoRenderMode["CameraFarPlane"] = 0] = "CameraFarPlane";
    VideoRenderMode[VideoRenderMode["CameraNearPlane"] = 1] = "CameraNearPlane";
    VideoRenderMode[VideoRenderMode["RenderTexture"] = 2] = "RenderTexture";
    VideoRenderMode[VideoRenderMode["MaterialOverride"] = 3] = "MaterialOverride";
})(VideoRenderMode || (VideoRenderMode = {}));
export class VideoPlayer extends Behaviour {
    renderer = null;
    playOnAwake = true;
    playOnEnable;
    aspectMode = AspectMode.None;
    renderMode;
    targetMaterialProperty;
    targetMaterialRenderer;
    targetTexture;
    time = 0;
    _playbackSpeed = 1;
    get playbackSpeed() {
        return this.videoElement?.playbackRate ?? this._playbackSpeed;
    }
    set playbackSpeed(val) {
        this._playbackSpeed = val;
        if (this.videoElement)
            this.videoElement.playbackRate = val;
    }
    _isLooping = false;
    get isLooping() {
        return this.videoElement?.loop ?? this._isLooping;
    }
    set isLooping(val) {
        this._isLooping = val;
        if (this.videoElement)
            this.videoElement.loop = val;
    }
    get currentTime() {
        return this.videoElement?.currentTime ?? this.time;
    }
    set currentTime(val) {
        if (this.videoElement) {
            this.videoElement.currentTime = val;
        }
        else
            this.time = val;
    }
    get isPlaying() {
        const video = this.videoElement;
        if (video) {
            return video.currentTime > 0 && !video.paused && !video.ended
                && video.readyState > video.HAVE_CURRENT_DATA;
        }
        return false;
    }
    get crossOrigin() {
        return this.videoElement?.crossOrigin ?? this._crossOrigin;
    }
    set crossOrigin(val) {
        this._crossOrigin = val;
        if (this.videoElement) {
            if (val !== null)
                this.videoElement.setAttribute("crossorigin", val);
            else
                this.videoElement.removeAttribute("crossorigin");
        }
    }
    get videoTexture() {
        return this._videoTexture;
    }
    _crossOrigin = "anonymous";
    audioOutputMode = VideoAudioOutputMode.AudioSource;
    source;
    clip = null;
    url = null;
    videoElement = null;
    _videoTexture = null;
    videoMaterial = null;
    _isPlaying = false;
    wasPlaying = false;
    setVideo(video) {
        this.clip = video;
        this.source = VideoSource.VideoClip;
        if (!this.videoElement)
            this.create(true);
        else {
            // TODO: how to prevent interruption error when another video is already playing
            this.videoElement.srcObject = video;
            if (this._isPlaying)
                this.videoElement.play();
            this.updateAspect();
        }
    }
    setClipURL(url) {
        if (this.url === url)
            return;
        // console.log("SET URL", url);
        this.url = url;
        this.source = VideoSource.Url;
        if (debug)
            console.log("set url", url);
        if (!this.videoElement)
            this.create(true);
        else {
            this.videoElement.src = url;
            if (this._isPlaying) {
                this.stop();
                this.play();
            }
        }
    }
    awake() {
        this.create(this.playOnAwake);
        window.addEventListener('visibilitychange', _evt => {
            switch (document.visibilityState) {
                case "hidden":
                    this.wasPlaying = this._isPlaying;
                    this.pause();
                    break;
                case "visible":
                    if (this.wasPlaying)
                        this.play();
                    break;
            }
        });
    }
    onEnable() {
        if (this.playOnEnable === true) {
            this.handleBeginPlaying(true);
        }
        if (this.screenspace) {
            this._overlay?.start();
        }
        else
            this._overlay?.stop();
    }
    onDisable() {
        this.pause();
    }
    onDestroy() {
        if (this.videoElement) {
            this.videoElement.parentElement?.removeChild(this.videoElement);
            this.videoElement = null;
        }
        if (this._videoTexture) {
            this._videoTexture.dispose();
            this._videoTexture = null;
        }
    }
    _receivedInput = false;
    constructor() {
        super();
        awaitInput(() => {
            this._receivedInput = true;
            this.updateVideoElementSettings();
        });
        this._targetObjects = [];
        if (getParam("videoscreenspace")) {
            window.addEventListener("keydown", evt => {
                if (evt.key === "f") {
                    this.screenspace = !this.screenspace;
                }
            });
        }
    }
    play() {
        if (!this.videoElement)
            return;
        if (this._isPlaying && !this.videoElement?.ended && !this.videoElement?.paused)
            return;
        this._isPlaying = true;
        if (!this._receivedInput)
            this.videoElement.muted = true;
        this.updateVideoElementSettings();
        this.videoElement?.play().catch(err => {
            console.warn(err);
        });
        if (debug)
            console.log("play", this.videoElement);
    }
    stop() {
        this._isPlaying = false;
        if (!this.videoElement)
            return;
        this.videoElement.currentTime = 0;
        this.videoElement.pause();
    }
    pause() {
        this._isPlaying = false;
        this.videoElement?.pause();
    }
    create(playAutomatically) {
        let src;
        switch (this.source) {
            case VideoSource.VideoClip:
                src = this.clip;
                break;
            case VideoSource.Url:
                src = this.url;
                break;
        }
        if (!src)
            return;
        // console.log(src, this);
        if (!this.videoElement) {
            this.videoElement = this.createVideoElement();
            this.context.domElement?.prepend(this.videoElement);
            // hide it because otherwise it would overlay the website with default css
            this.updateVideoElementStyles();
        }
        if (typeof src === "string") {
            this.videoElement.src = src;
            const str = this.videoElement["captureStream"]?.call(this.videoElement);
            this.clip = str;
        }
        else
            this.videoElement.srcObject = src;
        if (!this._videoTexture)
            this._videoTexture = new THREE.VideoTexture(this.videoElement);
        this._videoTexture.flipY = false;
        this._videoTexture.encoding = THREE.sRGBEncoding;
        this.handleBeginPlaying(playAutomatically);
        if (debug)
            console.log(this);
    }
    updateAspect() {
        if (this.aspectMode === AspectMode.None)
            return;
        this.startCoroutine(this.updateAspectImpl());
    }
    _overlay = null;
    get screenspace() {
        return this._overlay?.enabled ?? false;
    }
    set screenspace(val) {
        if (val) {
            if (!this._videoTexture)
                return;
            if (!this._overlay)
                this._overlay = new VideoOverlay(this.context);
            this._overlay.add(this._videoTexture);
        }
        else
            this._overlay?.remove(this._videoTexture);
        if (this._overlay)
            this._overlay.enabled = val;
    }
    _targetObjects;
    createVideoElement() {
        const video = document.createElement("video");
        if (this._crossOrigin)
            video.setAttribute("crossorigin", this._crossOrigin);
        if (debug)
            console.log("create video elment", video);
        return video;
    }
    handleBeginPlaying(playAutomatically) {
        if (!this.enabled)
            return;
        if (!this.videoElement)
            return;
        this._targetObjects.length = 0;
        let target = this.gameObject;
        switch (this.renderMode) {
            case VideoRenderMode.MaterialOverride:
                target = this.targetMaterialRenderer?.gameObject;
                if (!target)
                    target = GameObject.getComponent(this.gameObject, Renderer)?.gameObject;
                break;
            case VideoRenderMode.RenderTexture:
                console.error("VideoPlayer renderTexture not implemented yet. Please use material override instead");
                return;
        }
        if (!target) {
            console.error("Missing target for video material renderer", this.name, VideoRenderMode[this.renderMode], this);
            return;
        }
        const mat = target["material"];
        if (mat) {
            this._targetObjects.push(target);
            if (mat !== this.videoMaterial) {
                this.videoMaterial = mat.clone();
                target["material"] = this.videoMaterial;
            }
            if (!this.targetMaterialProperty) {
                this.videoMaterial.map = this._videoTexture;
            }
            else {
                switch (this.targetMaterialProperty) {
                    default:
                        this.videoMaterial.map = this._videoTexture;
                        break;
                    // doesnt render:
                    // case "emissiveTexture":
                    //     console.log(this.videoMaterial);
                    //     // (this.videoMaterial as any).map = this.videoTexture;
                    //     (this.videoMaterial as any).emissive?.set(1,1,1);// = this.videoTexture;
                    //     (this.videoMaterial as any).emissiveMap = this.videoTexture;
                    //     break;
                }
            }
        }
        else {
            console.warn("Can not play video, no material found, this might be a multimaterial case which is not supported yet");
            return;
        }
        this.updateVideoElementSettings();
        this.updateVideoElementStyles();
        if (playAutomatically)
            this.play();
    }
    updateVideoElementSettings() {
        if (!this.videoElement)
            return;
        this.videoElement.loop = this._isLooping;
        this.videoElement.currentTime = this.currentTime;
        this.videoElement.playbackRate = this._playbackSpeed;
        // dont open in fullscreen on ios
        this.videoElement.playsInline = true;
        this.videoElement.muted = !this._receivedInput && this.audioOutputMode !== VideoAudioOutputMode.None;
        if (this.playOnAwake || this.playOnEnable)
            this.videoElement.autoplay = true;
    }
    updateVideoElementStyles() {
        if (!this.videoElement)
            return;
        // set style here so preview frame is rendered
        // set display and selectable because otherwise is interfers with input/focus e.g. breaks orbit control
        this.videoElement.style.userSelect = "none";
        this.videoElement.style.visibility = "hidden";
        this.videoElement.style.display = "none";
        this.updateAspect();
    }
    _updateAspectRoutineId = -1;
    *updateAspectImpl() {
        const id = ++this._updateAspectRoutineId;
        const lastAspect = undefined;
        const stream = this.clip;
        while (id === this._updateAspectRoutineId && this.aspectMode !== AspectMode.None && this.clip && stream === this.clip && this._isPlaying) {
            if (!stream || typeof stream === "string") {
                return;
            }
            let aspect = undefined;
            for (const track of stream.getVideoTracks()) {
                const settings = track.getSettings();
                if (settings && settings.width && settings.height) {
                    aspect = settings.width / settings.height;
                    break;
                }
                // on firefox capture canvas stream works but looks like 
                // the canvas stream track doesnt contain settings?!!?
                else {
                    aspect = this.context.renderer.domElement.clientWidth / this.context.renderer.domElement.clientHeight;
                }
            }
            if (aspect === undefined) {
                for (let i = 0; i < 10; i++)
                    yield;
                if (!this.isPlaying)
                    break;
                continue;
            }
            if (lastAspect === aspect) {
                yield;
                continue;
            }
            for (const obj of this._targetObjects) {
                let worldAspect = 1;
                if (obj.parent) {
                    const parentScale = getWorldScale(obj.parent);
                    worldAspect = parentScale.x / parentScale.y;
                }
                switch (this.aspectMode) {
                    case AspectMode.AdjustHeight:
                        obj.scale.y = 1 / aspect * obj.scale.x * worldAspect;
                        break;
                    case AspectMode.AdjustWidth:
                        obj.scale.x = aspect * obj.scale.y * worldAspect;
                        break;
                }
            }
            for (let i = 0; i < 3; i++)
                yield;
        }
    }
}
__decorate([
    serializable(Object3D)
], VideoPlayer.prototype, "renderer", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "playOnAwake", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "playOnEnable", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "aspectMode", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "renderMode", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "targetMaterialProperty", void 0);
__decorate([
    serializable(Renderer)
], VideoPlayer.prototype, "targetMaterialRenderer", void 0);
__decorate([
    serializable(Texture)
], VideoPlayer.prototype, "targetTexture", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "time", void 0);
__decorate([
    serializable()
], VideoPlayer.prototype, "playbackSpeed", null);
__decorate([
    serializable()
], VideoPlayer.prototype, "isLooping", null);
class VideoOverlay {
    context;
    constructor(context) {
        this.context = context;
        this._input = new VideoOverlayInput(this);
    }
    get enabled() {
        return this._isInScreenspaceMode;
    }
    set enabled(val) {
        if (val)
            this.start();
        else
            this.stop();
    }
    add(video) {
        if (this._videos.indexOf(video) === -1) {
            this._videos.push(video);
        }
    }
    remove(video) {
        if (!video)
            return;
        const index = this._videos.indexOf(video);
        if (index >= 0) {
            this._videos.splice(index, 1);
        }
    }
    start() {
        if (this._isInScreenspaceMode)
            return;
        if (this._videos.length < 0)
            return;
        const texture = this._videos[this._videos.length - 1];
        if (!texture)
            return;
        this._isInScreenspaceMode = true;
        if (!this._screenspaceModeQuad) {
            this._screenspaceModeQuad = ObjectUtils.createPrimitive(PrimitiveType.Quad, {
                material: new ScreenspaceTexture(texture)
            });
            if (!this._screenspaceModeQuad)
                return;
            this._screenspaceModeQuad.geometry.scale(2, 2, 2);
        }
        const quad = this._screenspaceModeQuad;
        this.context.scene.add(quad);
        this.updateScreenspaceMaterialUniforms();
        const mat = quad.material;
        mat?.reset();
        this._input?.enable(mat);
    }
    stop() {
        this._isInScreenspaceMode = false;
        if (this._screenspaceModeQuad) {
            this._input?.disable();
            this._screenspaceModeQuad.removeFromParent();
        }
    }
    updateScreenspaceMaterialUniforms() {
        const mat = this._screenspaceModeQuad?.material;
        if (!mat)
            return;
        // mat.videoAspect = this.videoTexture?.image?.width / this.videoTexture?.image?.height;
        mat.screenAspect = this.context.domElement.clientWidth / this.context.domElement.clientHeight;
    }
    _videos = [];
    _screenspaceModeQuad;
    _isInScreenspaceMode = false;
    _input;
}
class VideoOverlayInput {
    _onResizeScreenFn;
    _onKeyUpFn;
    _onMouseWheelFn;
    context;
    overlay;
    constructor(overlay) {
        this.overlay = overlay;
        this.context = overlay.context;
    }
    _material;
    enable(mat) {
        this._material = mat;
        window.addEventListener("resize", this._onResizeScreenFn = () => {
            this.overlay.updateScreenspaceMaterialUniforms();
        });
        window.addEventListener("keyup", this._onKeyUpFn = (args) => {
            if (args.key === "Escape")
                this.overlay.stop();
        });
        window.addEventListener("wheel", this._onMouseWheelFn = (args) => {
            if (this.overlay.enabled) {
                mat.zoom += args.deltaY * .0005;
                args.preventDefault();
            }
        }, { passive: false });
        const delta = new Vector2();
        window.addEventListener("mousemove", (args) => {
            if (this.overlay.enabled && this.context.input.getPointerPressed(0)) {
                const normalizedMovement = new Vector2(args.movementX, args.movementY);
                normalizedMovement.x /= this.context.domElement.clientWidth;
                normalizedMovement.y /= this.context.domElement.clientHeight;
                delta.set(normalizedMovement.x, normalizedMovement.y);
                delta.multiplyScalar(mat.zoom / -this.context.time.deltaTime * .01);
                mat.offset = mat.offset.add(delta);
            }
        });
        window.addEventListener("pointermove", (args) => {
            if (this.overlay.enabled && this.context.input.getPointerPressed(0)) {
                const count = this.context.input.getTouchesPressedCount();
                if (count === 1) {
                    delta.set(args.movementX, args.movementY);
                    delta.multiplyScalar(mat.zoom * -this.context.time.deltaTime * .05);
                    mat.offset = mat.offset.add(delta);
                }
            }
        });
        let lastTouchStartTime = 0;
        window.addEventListener("touchstart", e => {
            if (e.touches.length < 2) {
                if (this.context.time.time - lastTouchStartTime < .3) {
                    this.overlay.stop();
                }
                lastTouchStartTime = this.context.time.time;
                return;
            }
            this._isPinching = true;
            this._lastPinch = 0;
        });
        window.addEventListener("touchmove", e => {
            if (!this._isPinching || !this._material)
                return;
            const touch1 = e.touches[0];
            const touch2 = e.touches[1];
            const dx = touch1.clientX - touch2.clientX;
            const dy = touch1.clientY - touch2.clientY;
            const distance = Math.sqrt(dx * dx + dy * dy);
            if (this._lastPinch !== 0) {
                const delta = distance - this._lastPinch;
                this._material.zoom -= delta * .004;
            }
            this._lastPinch = distance;
        });
        window.addEventListener("touchend", () => {
            this._isPinching = false;
        });
    }
    _isPinching = false;
    _lastPinch = 0;
    disable() {
        if (this._onResizeScreenFn) {
            window.removeEventListener("resize", this._onResizeScreenFn);
            this._onResizeScreenFn = undefined;
        }
        if (this._onKeyUpFn) {
            window.removeEventListener("keyup", this._onKeyUpFn);
            this._onKeyUpFn = undefined;
        }
        if (this._onMouseWheelFn) {
            window.removeEventListener("wheel", this._onMouseWheelFn);
            this._onMouseWheelFn = undefined;
        }
    }
}
class ScreenspaceTexture extends ShaderMaterial {
    set screenAspect(val) {
        this.uniforms["screenAspect"].value = val;
        this.needsUpdate = true;
    }
    set offset(vec) {
        const val = this.uniforms["offsetScale"].value;
        val.x = vec.x;
        val.y = vec.y;
        // console.log(val);
        this.uniforms["offsetScale"].value = val;
        this.needsUpdate = true;
    }
    _offset = new Vector2();
    get offset() {
        const val = this.uniforms["offsetScale"].value;
        this._offset.set(val.x, val.y);
        return this._offset;
    }
    set zoom(val) {
        const zoom = this.uniforms["offsetScale"].value;
        if (val < .001)
            val = .001;
        zoom.z = val;
        // zoom.z = this.maxZoom - val;
        // zoom.z /= this.maxZoom;
        this.needsUpdate = true;
    }
    get zoom() {
        return this.uniforms["offsetScale"].value.z; // * this.maxZoom;
    }
    reset() {
        this.offset = this.offset.set(0, 0);
        this.zoom = 1;
        this.needsUpdate = true;
    }
    // maxZoom : number = 10
    constructor(tex) {
        super();
        this.uniforms = {
            map: { value: tex },
            screenAspect: { value: 1 },
            offsetScale: { value: new Vector4(0, 0, 1, 1) }
        };
        this.vertexShader = `
        uniform sampler2D map;
        uniform float screenAspect;
        uniform vec4 offsetScale;
        varying vec2 vUv;

        void main() {

            gl_Position = vec4( position , 1.0 );
            vUv = uv;
            vUv.y = 1. - vUv.y;

            // fit into screen
            ivec2 res = textureSize(map, 0);
            float videoAspect = float(res.x) / float(res.y);
            float aspect = videoAspect / screenAspect;
            if(aspect >= 1.0) 
            {
                vUv.y = vUv.y * aspect;
                float offset = (1. - aspect) * .5;
                vUv.y = vUv.y + offset;
            }
            else
            {
                vUv.x = vUv.x / aspect;
                float offset = (1. - 1. / aspect) * .5;
                vUv.x = vUv.x + offset;
            }

            vUv.x -= .5;
            vUv.y -= .5;

            vUv.x *= offsetScale.z;
            vUv.y *= offsetScale.z;
            vUv.x += offsetScale.x;
            vUv.y += offsetScale.y;

            vUv.x += .5;
            vUv.y += .5;
        }

        `;
        this.fragmentShader = `
        uniform sampler2D map;
        varying vec2 vUv;
        void main() {
            if(vUv.x < 0. || vUv.x > 1. || vUv.y < 0. || vUv.y > 1.)
                gl_FragColor = vec4(0., 0., 0., 1.);
            else
                gl_FragColor = texture2D(map, vUv);
        }
        `;
    }
}
//# sourceMappingURL=VideoPlayer.js.map